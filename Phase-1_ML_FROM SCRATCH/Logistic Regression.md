## ğŸ§  Logistic Regression From Scratch (Using NumPy)

## ğŸ“Œ file Overview

This file implements **Binary Logistic Regression from scratch** using only **NumPy** â€” without using any machine learning libraries 

The goal of this implementation is to deeply understand:

* How Logistic Regression works mathematically
* How the Sigmoid function converts linear output into probabilities
* How Binary Cross-Entropy relates to gradient updates
* How Gradient Descent optimizes model parameters

---

## ğŸ“Š Problem Type

Binary Classification

Example:

| Input (x) | Output (y) |
|-----------|------------|
| 1         | 0          |
| 2         | 0          |
| 3         | 1          |
| 4         | 1          |

The model learns to predict whether a sample belongs to class **0 or 1**.

---

## ğŸ§® Background

### 1ï¸âƒ£ Linear Equation

```
z = w * x + b
```

### 2ï¸âƒ£ Sigmoid Function

```
Ïƒ(z) = 1 / (1 + e^(-z))
```

This converts any real number into a value between **0 and 1** ( statics probability).

### 3ï¸âƒ£ Prediction Rule

```
Å· = 1 if Ïƒ(z) â‰¥ 0.5, else 0
```

### 4ï¸âƒ£ Gradients Used

```
dw = (1/n) * Î£ (Å· - y) * x
db = (1/n) * Î£ (Å· - y)
```


## ğŸš€ Code Structure

```python

---
